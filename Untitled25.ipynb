{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install necessary packages (only once)\n",
        "!pip install -q kagglehub seaborn scikit-plot\n"
      ],
      "metadata": {
        "id": "auKkNAGIpUmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# âœ… Download dataset\n",
        "path = kagglehub.dataset_download(\"deadskull7/fer2013\")\n",
        "print(\"Dataset downloaded at:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZFGymSZpZ-g",
        "outputId": "c49d192e-f2a1-492e-ac5f-cf125c52fb28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded at: /kaggle/input/fer2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(f\"{path}/fer2013.csv\")\n",
        "\n",
        "# Emotion label mapping\n",
        "emotion_map = {\n",
        "    0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\",\n",
        "    4: \"Sad\", 5: \"Surprise\", 6: \"Neutral\"\n",
        "}\n",
        "df[\"emotion_label\"] = df[\"emotion\"].map(emotion_map)\n"
      ],
      "metadata": {
        "id": "_ldkNKJjpbHH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pixels from string to array\n",
        "df['pixels'] = df['pixels'].apply(lambda x: np.array(x.split(), dtype='float32'))\n",
        "\n",
        "# Normalize to [0, 1]\n",
        "X = np.stack(df['pixels'].values).reshape(-1, 48, 48, 1) / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y = pd.get_dummies(df['emotion']).values\n"
      ],
      "metadata": {
        "id": "lwBX-JSvpdtY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def apply_clahe(image):\n",
        "    image = (image * 255).astype(np.uint8).reshape(48, 48)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    image_clahe = clahe.apply(image)\n",
        "    return np.stack([image_clahe]*3, axis=-1) / 255.0\n",
        "\n",
        "X_rgb = np.array([apply_clahe(img) for img in X])\n"
      ],
      "metadata": {
        "id": "0hM4RwuMpkKJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_rgb = X_rgb[df[\"Usage\"] == \"Training\"]\n",
        "y_train = y[df[\"Usage\"] == \"Training\"]\n",
        "\n",
        "X_valid_rgb = X_rgb[df[\"Usage\"] == \"PublicTest\"]\n",
        "y_valid = y[df[\"Usage\"] == \"PublicTest\"]\n"
      ],
      "metadata": {
        "id": "J5pENJRRpoK5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "wWAIERLDppf4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df['emotion']),\n",
        "    y=df[df['Usage'] == 'Training']['emotion']\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "qcAMDIjXprkY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Initial build: VGG frozen\n",
        "def build_vgg19_model():\n",
        "    base = VGG19(include_top=False, weights='imagenet', input_tensor=Input(shape=(48, 48, 3)))\n",
        "    base.trainable = False  # Freeze VGG\n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    out = Dense(7, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=out)\n",
        "    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_vgg19_model()\n"
      ],
      "metadata": {
        "id": "iw41Dl-9pszA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "\n",
        "class SaveEvery10Epochs(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            self.model.save(f\"vgg19_fer_epoch_{epoch+1}.keras\")\n",
        "            print(f\"âœ… Saved model at epoch {epoch+1}\")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen.flow(X_train_rgb, y_train, batch_size=32),\n",
        "    validation_data=(X_valid_rgb, y_valid),\n",
        "    epochs=10,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, SaveEvery10Epochs()],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN-2ym_Npuhf",
        "outputId": "ad34bc2a-2628-4931-b506-319ba1283bfd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_28']\n",
            "Received: inputs=Tensor(shape=(None, 48, 48, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 45ms/step - accuracy: 0.1578 - loss: 2.1049 - val_accuracy: 0.2340 - val_loss: 1.8879\n",
            "Epoch 2/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 40ms/step - accuracy: 0.1971 - loss: 1.9432 - val_accuracy: 0.2533 - val_loss: 1.8453\n",
            "Epoch 3/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.2312 - loss: 1.8659 - val_accuracy: 0.2867 - val_loss: 1.8049\n",
            "Epoch 4/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.2368 - loss: 1.8710 - val_accuracy: 0.3165 - val_loss: 1.7636\n",
            "Epoch 5/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 40ms/step - accuracy: 0.2430 - loss: 1.8398 - val_accuracy: 0.3305 - val_loss: 1.7412\n",
            "Epoch 6/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 41ms/step - accuracy: 0.2548 - loss: 1.8270 - val_accuracy: 0.3126 - val_loss: 1.7607\n",
            "Epoch 7/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 39ms/step - accuracy: 0.2518 - loss: 1.8095 - val_accuracy: 0.3193 - val_loss: 1.7455\n",
            "Epoch 8/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 41ms/step - accuracy: 0.2587 - loss: 1.8101 - val_accuracy: 0.3215 - val_loss: 1.7264\n",
            "Epoch 9/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 41ms/step - accuracy: 0.2627 - loss: 1.8116 - val_accuracy: 0.3254 - val_loss: 1.7302\n",
            "Epoch 10/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2664 - loss: 1.7878âœ… Saved model at epoch 10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 41ms/step - accuracy: 0.2664 - loss: 1.7878 - val_accuracy: 0.3307 - val_loss: 1.7184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze top convolution blocks of VGG19\n",
        "for layer in model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune for 30â€“40 more epochs\n",
        "history_ft = model.fit(\n",
        "    train_gen.flow(X_train_rgb, y_train, batch_size=32),\n",
        "    validation_data=(X_valid_rgb, y_valid),\n",
        "    epochs=40,\n",
        "    initial_epoch=10,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, SaveEvery10Epochs()],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VtzotOypv5_",
        "outputId": "6cb9624b-4402-445f-b37f-cd214faa29c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 55ms/step - accuracy: 0.2832 - loss: 1.7997 - val_accuracy: 0.3249 - val_loss: 1.7222\n",
            "Epoch 12/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3219 - loss: 1.6824 - val_accuracy: 0.4076 - val_loss: 1.5749\n",
            "Epoch 13/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3441 - loss: 1.6621 - val_accuracy: 0.3856 - val_loss: 1.5991\n",
            "Epoch 14/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.3646 - loss: 1.6012 - val_accuracy: 0.4107 - val_loss: 1.5417\n",
            "Epoch 15/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.3803 - loss: 1.5632 - val_accuracy: 0.4422 - val_loss: 1.4576\n",
            "Epoch 16/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.3938 - loss: 1.5487 - val_accuracy: 0.4244 - val_loss: 1.4913\n",
            "Epoch 17/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.4055 - loss: 1.5184 - val_accuracy: 0.4026 - val_loss: 1.5180\n",
            "Epoch 18/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.4113 - loss: 1.4857 - val_accuracy: 0.4653 - val_loss: 1.4013\n",
            "Epoch 19/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4267 - loss: 1.4684 - val_accuracy: 0.4868 - val_loss: 1.3504\n",
            "Epoch 20/40\n",
            "\u001b[1m897/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4360 - loss: 1.4365âœ… Saved model at epoch 20\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 52ms/step - accuracy: 0.4360 - loss: 1.4365 - val_accuracy: 0.4854 - val_loss: 1.3612\n",
            "Epoch 21/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4387 - loss: 1.4376 - val_accuracy: 0.4976 - val_loss: 1.3442\n",
            "Epoch 22/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.4492 - loss: 1.3832 - val_accuracy: 0.5040 - val_loss: 1.3056\n",
            "Epoch 23/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4539 - loss: 1.3822 - val_accuracy: 0.4876 - val_loss: 1.3577\n",
            "Epoch 24/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.4579 - loss: 1.3575 - val_accuracy: 0.4400 - val_loss: 1.4729\n",
            "Epoch 25/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.4619 - loss: 1.3637 - val_accuracy: 0.4753 - val_loss: 1.3721\n",
            "Epoch 26/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 51ms/step - accuracy: 0.4668 - loss: 1.3373 - val_accuracy: 0.5202 - val_loss: 1.2685\n",
            "Epoch 27/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4749 - loss: 1.3192 - val_accuracy: 0.5077 - val_loss: 1.3005\n",
            "Epoch 28/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.4821 - loss: 1.2910 - val_accuracy: 0.5104 - val_loss: 1.3139\n",
            "Epoch 29/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4877 - loss: 1.2916 - val_accuracy: 0.4801 - val_loss: 1.3856\n",
            "Epoch 30/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4909 - loss: 1.2678âœ… Saved model at epoch 30\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.4909 - loss: 1.2678 - val_accuracy: 0.4918 - val_loss: 1.3216\n",
            "Epoch 31/40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4879 - loss: 1.2709 - val_accuracy: 0.5202 - val_loss: 1.2759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    min_lr=1e-7\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bw2G4QSxy5gd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"vgg19_fer_epoch_30.keras\")\n"
      ],
      "metadata": {
        "id": "xvVx-e-Vy73u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "i0JwuFRSzUya"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-7)\n",
        "\n",
        "# Make sure SaveEvery10Epochs is still available\n"
      ],
      "metadata": {
        "id": "Aaf6M4xZzX2v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resume = model.fit(\n",
        "    train_gen.flow(X_train_rgb, y_train, batch_size=32),\n",
        "    validation_data=(X_valid_rgb, y_valid),\n",
        "    initial_epoch=30,\n",
        "    epochs=80,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery10Epochs()],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSdMFMISzaJZ",
        "outputId": "4079f5a6-f869-46c7-ef24-15cdf291d9bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.4970 - loss: 1.2554 - val_accuracy: 0.4845 - val_loss: 1.3443 - learning_rate: 1.0000e-05\n",
            "Epoch 32/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4945 - loss: 1.2602 - val_accuracy: 0.5127 - val_loss: 1.2741 - learning_rate: 1.0000e-05\n",
            "Epoch 33/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.4998 - loss: 1.2407 - val_accuracy: 0.5300 - val_loss: 1.2424 - learning_rate: 1.0000e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5074 - loss: 1.2157 - val_accuracy: 0.5263 - val_loss: 1.2646 - learning_rate: 1.0000e-05\n",
            "Epoch 35/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5148 - loss: 1.2020 - val_accuracy: 0.5258 - val_loss: 1.2629 - learning_rate: 1.0000e-05\n",
            "Epoch 36/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5143 - loss: 1.2113 - val_accuracy: 0.5283 - val_loss: 1.2501 - learning_rate: 1.0000e-05\n",
            "Epoch 37/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5173 - loss: 1.1957 - val_accuracy: 0.5283 - val_loss: 1.2625 - learning_rate: 1.0000e-05\n",
            "Epoch 38/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 49ms/step - accuracy: 0.5153 - loss: 1.1942 - val_accuracy: 0.5405 - val_loss: 1.2167 - learning_rate: 1.0000e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.5265 - loss: 1.1656 - val_accuracy: 0.5216 - val_loss: 1.2708 - learning_rate: 1.0000e-05\n",
            "Epoch 40/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5297 - loss: 1.1504âœ… Saved model at epoch 40\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.5297 - loss: 1.1504 - val_accuracy: 0.5389 - val_loss: 1.2267 - learning_rate: 1.0000e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5372 - loss: 1.1376 - val_accuracy: 0.5467 - val_loss: 1.2053 - learning_rate: 1.0000e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5316 - loss: 1.1323 - val_accuracy: 0.5539 - val_loss: 1.1912 - learning_rate: 1.0000e-05\n",
            "Epoch 43/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5426 - loss: 1.1287 - val_accuracy: 0.5280 - val_loss: 1.2330 - learning_rate: 1.0000e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5451 - loss: 1.1242 - val_accuracy: 0.5327 - val_loss: 1.2468 - learning_rate: 1.0000e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5396 - loss: 1.1118 - val_accuracy: 0.5386 - val_loss: 1.2355 - learning_rate: 1.0000e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5465 - loss: 1.1016 - val_accuracy: 0.5294 - val_loss: 1.2723 - learning_rate: 1.0000e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5500 - loss: 1.1142\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5500 - loss: 1.1142 - val_accuracy: 0.5464 - val_loss: 1.2006 - learning_rate: 1.0000e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5586 - loss: 1.0633 - val_accuracy: 0.5578 - val_loss: 1.1878 - learning_rate: 5.0000e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 51ms/step - accuracy: 0.5662 - loss: 1.0511 - val_accuracy: 0.5506 - val_loss: 1.1991 - learning_rate: 5.0000e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5736 - loss: 1.0463âœ… Saved model at epoch 50\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.5736 - loss: 1.0463 - val_accuracy: 0.5481 - val_loss: 1.2118 - learning_rate: 5.0000e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.5711 - loss: 1.0339 - val_accuracy: 0.5656 - val_loss: 1.1844 - learning_rate: 5.0000e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.5784 - loss: 1.0105 - val_accuracy: 0.5676 - val_loss: 1.1640 - learning_rate: 5.0000e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5829 - loss: 1.0105 - val_accuracy: 0.5595 - val_loss: 1.1940 - learning_rate: 5.0000e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5807 - loss: 1.0121 - val_accuracy: 0.5634 - val_loss: 1.1828 - learning_rate: 5.0000e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5860 - loss: 0.9936 - val_accuracy: 0.5648 - val_loss: 1.1679 - learning_rate: 5.0000e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5863 - loss: 0.9976 - val_accuracy: 0.5578 - val_loss: 1.1930 - learning_rate: 5.0000e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m897/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5881 - loss: 0.9877\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5881 - loss: 0.9877 - val_accuracy: 0.5676 - val_loss: 1.1716 - learning_rate: 5.0000e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5957 - loss: 0.9633 - val_accuracy: 0.5673 - val_loss: 1.1898 - learning_rate: 2.5000e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6044 - loss: 0.9651 - val_accuracy: 0.5690 - val_loss: 1.1864 - learning_rate: 2.5000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¦ Modified callback: Save every 5 epochs instead of 10\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class SaveEvery5Epochs(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            filename = f\"vgg19_fer_epoch_{epoch+1}.keras\"\n",
        "            self.model.save(filename)\n",
        "            print(f\"âœ… Saved model at epoch {epoch+1}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "u0TvEbIf5UD7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ğŸ” Load the saved model from epoch 50\n",
        "model = load_model(\"vgg19_fer_epoch_50.keras\")\n",
        "\n",
        "# ğŸ” Resume training from epoch 50 â†’ 80\n",
        "history_resume = model.fit(\n",
        "    train_gen.flow(X_train_rgb, y_train, batch_size=32),\n",
        "    validation_data=(X_valid_rgb, y_valid),\n",
        "    initial_epoch=50,\n",
        "    epochs=80,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery5Epochs()],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XWcx3EP5ee9",
        "outputId": "384ff58f-efe5-4324-c4b5-d3265d5f35fe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 56ms/step - accuracy: 0.5743 - loss: 1.0173 - val_accuracy: 0.5525 - val_loss: 1.2046 - learning_rate: 5.0000e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.5791 - loss: 1.0171 - val_accuracy: 0.5386 - val_loss: 1.2340 - learning_rate: 5.0000e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5761 - loss: 1.0228 - val_accuracy: 0.5645 - val_loss: 1.1916 - learning_rate: 5.0000e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5803 - loss: 1.0006 - val_accuracy: 0.5595 - val_loss: 1.1834 - learning_rate: 5.0000e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5783 - loss: 1.0078âœ… Saved model at epoch 55\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.5783 - loss: 1.0078 - val_accuracy: 0.5511 - val_loss: 1.2051 - learning_rate: 5.0000e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5875 - loss: 0.9793 - val_accuracy: 0.5578 - val_loss: 1.2108 - learning_rate: 5.0000e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5916 - loss: 0.9830 - val_accuracy: 0.5628 - val_loss: 1.1897 - learning_rate: 5.0000e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5868 - loss: 0.9882 - val_accuracy: 0.5511 - val_loss: 1.2154 - learning_rate: 5.0000e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5887 - loss: 0.9868\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.5887 - loss: 0.9868 - val_accuracy: 0.5548 - val_loss: 1.2022 - learning_rate: 5.0000e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5939 - loss: 0.9711âœ… Saved model at epoch 60\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 50ms/step - accuracy: 0.5939 - loss: 0.9711 - val_accuracy: 0.5768 - val_loss: 1.1695 - learning_rate: 2.5000e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.6021 - loss: 0.9439 - val_accuracy: 0.5701 - val_loss: 1.1840 - learning_rate: 2.5000e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6092 - loss: 0.9406 - val_accuracy: 0.5665 - val_loss: 1.1982 - learning_rate: 2.5000e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6059 - loss: 0.9462 - val_accuracy: 0.5651 - val_loss: 1.1873 - learning_rate: 2.5000e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6093 - loss: 0.9447 - val_accuracy: 0.5653 - val_loss: 1.1900 - learning_rate: 2.5000e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m897/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6054 - loss: 0.9442\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
            "âœ… Saved model at epoch 65\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6054 - loss: 0.9442 - val_accuracy: 0.5606 - val_loss: 1.1882 - learning_rate: 2.5000e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6106 - loss: 0.9224 - val_accuracy: 0.5673 - val_loss: 1.1904 - learning_rate: 1.2500e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 51ms/step - accuracy: 0.6157 - loss: 0.9119 - val_accuracy: 0.5626 - val_loss: 1.1848 - learning_rate: 1.2500e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load last saved model\n",
        "model = load_model(\"vgg19_fer_epoch_65.keras\")\n",
        "\n",
        "# Re-compile with low learning rate\n",
        "model.compile(optimizer=Adam(1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define ReduceLROnPlateau and EarlyStopping again (if not already defined)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Save every 5 epochs\n",
        "class SaveEvery5Epochs(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            self.model.save(f\"vgg19_fer_epoch_{epoch+1}.keras\")\n",
        "            print(f\"âœ… Saved model at epoch {epoch+1}\")\n",
        "\n",
        "# Resume training from epoch 65 to 80\n",
        "history_resume = model.fit(\n",
        "    train_gen.flow(X_train_rgb, y_train, batch_size=32),\n",
        "    validation_data=(X_valid_rgb, y_valid),\n",
        "    initial_epoch=65,\n",
        "    epochs=80,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery5Epochs()],\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68PUhLnA_A9N",
        "outputId": "ea15dc53-4ad6-4f13-f5e9-b54cefbfe7ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 59ms/step - accuracy: 0.6145 - loss: 0.9287 - val_accuracy: 0.5709 - val_loss: 1.1786 - learning_rate: 1.0000e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6150 - loss: 0.9234 - val_accuracy: 0.5678 - val_loss: 1.1760 - learning_rate: 1.0000e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6159 - loss: 0.9197 - val_accuracy: 0.5712 - val_loss: 1.1857 - learning_rate: 1.0000e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6180 - loss: 0.9153 - val_accuracy: 0.5709 - val_loss: 1.1750 - learning_rate: 1.0000e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6122 - loss: 0.9154âœ… Saved model at epoch 70\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 58ms/step - accuracy: 0.6122 - loss: 0.9154 - val_accuracy: 0.5687 - val_loss: 1.1679 - learning_rate: 1.0000e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6184 - loss: 0.9156 - val_accuracy: 0.5729 - val_loss: 1.1756 - learning_rate: 1.0000e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6177 - loss: 0.9171 - val_accuracy: 0.5681 - val_loss: 1.1786 - learning_rate: 1.0000e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6145 - loss: 0.9221\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.6146 - loss: 0.9221 - val_accuracy: 0.5704 - val_loss: 1.1821 - learning_rate: 1.0000e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6222 - loss: 0.9205 - val_accuracy: 0.5692 - val_loss: 1.1851 - learning_rate: 5.0000e-07\n",
            "Epoch 75/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6197 - loss: 0.9072âœ… Saved model at epoch 75\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 56ms/step - accuracy: 0.6197 - loss: 0.9072 - val_accuracy: 0.5720 - val_loss: 1.1758 - learning_rate: 5.0000e-07\n",
            "Epoch 76/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6186 - loss: 0.9052\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 50ms/step - accuracy: 0.6186 - loss: 0.9052 - val_accuracy: 0.5723 - val_loss: 1.1825 - learning_rate: 5.0000e-07\n",
            "Epoch 77/80\n",
            "\u001b[1m898/898\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 51ms/step - accuracy: 0.6241 - loss: 0.8961 - val_accuracy: 0.5712 - val_loss: 1.1815 - learning_rate: 2.5000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
        "import tensorflow as tf\n",
        "\n",
        "# âœ… Mixed Precision for better GPU utilization\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# âœ… Load latest model from epoch 75\n",
        "model = load_model(\"vgg19_fer_epoch_75.keras\")\n",
        "\n",
        "# âœ… Freeze shallow layers\n",
        "for layer in model.layers[:22]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[22:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# âœ… Cosine Annealing Scheduler\n",
        "lr_schedule = CosineDecayRestarts(\n",
        "    initial_learning_rate=5e-6,\n",
        "    first_decay_steps=10,\n",
        "    t_mul=2.0,\n",
        "    m_mul=0.9\n",
        ")\n",
        "\n",
        "# âœ… Ensure final layer is float32\n",
        "model.layers[-1]._dtype_policy = mixed_precision.Policy(\"float32\")\n",
        "\n",
        "# âœ… Recompile\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=lr_schedule),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# âœ… Dataset prep\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train_rgb, y_train)).shuffle(10000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_valid_rgb, y_valid)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# âœ… Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "class SaveEvery5Epochs(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            self.model.save(f\"vgg19_fer_epoch_{epoch+1}.keras\")\n",
        "            print(f\"âœ… Saved model at epoch {epoch+1}\")\n",
        "\n",
        "# âœ… Train from epoch 75 to 100\n",
        "history_resume = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    initial_epoch=75,\n",
        "    epochs=100,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery5Epochs()],\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "KUPoBTWhFdbL",
        "outputId": "20a47d65-f873-4171-f158-9e203fc95665"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 38 variables whereas the saved optimizer has 34 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 0 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 50ms/step - accuracy: 0.6549 - loss: 0.8311 - val_accuracy: 0.5743 - val_loss: 1.1700 - learning_rate: 1.7784e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.6534 - loss: 0.8237 - val_accuracy: 0.5731 - val_loss: 1.1673 - learning_rate: 1.6641e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.6569 - loss: 0.8184 - val_accuracy: 0.5756 - val_loss: 1.1664 - learning_rate: 2.3702e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6649 - loss: 0.8113 - val_accuracy: 0.5751 - val_loss: 1.1658 - learning_rate: 1.5260e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m448/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6615 - loss: 0.8106âœ… Saved model at epoch 80\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 39ms/step - accuracy: 0.6615 - loss: 0.8106 - val_accuracy: 0.5745 - val_loss: 1.1657 - learning_rate: 3.1968e-07\n",
            "Epoch 81/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6560 - loss: 0.8136 - val_accuracy: 0.5748 - val_loss: 1.1658 - learning_rate: 2.1356e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.6627 - loss: 0.8059 - val_accuracy: 0.5754 - val_loss: 1.1655 - learning_rate: 1.8797e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6619 - loss: 0.8096 - val_accuracy: 0.5751 - val_loss: 1.1653 - learning_rate: 1.3860e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.6589 - loss: 0.8120 - val_accuracy: 0.5748 - val_loss: 1.1652 - learning_rate: 8.0061e-07\n",
            "Epoch 85/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6610 - loss: 0.8057âœ… Saved model at epoch 85\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.6610 - loss: 0.8057 - val_accuracy: 0.5745 - val_loss: 1.1654 - learning_rate: 2.9676e-07\n",
            "Epoch 86/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6533 - loss: 0.8206"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c4f2a8de6e07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# âœ… Train from epoch 75 to 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m history_resume = model.fit(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mlearning_rate\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             ):\n\u001b[0;32m--> 636\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    637\u001b[0m                     \u001b[0;34m\"This optimizer was created with a `LearningRateSchedule`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                     \u001b[0;34m\" object as its `learning_rate` constructor argument, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Continue training from Epoch 75 to 100 â€” without ReduceLROnPlateau\n",
        "history_resume = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    initial_epoch=85,\n",
        "    epochs=100,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, SaveEvery5Epochs()],  # Removed reduce_lr\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Sz9AGxG6wJ",
        "outputId": "cb50a725-a795-46bc-f4d5-f8deb1261ccf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.6571 - loss: 0.8200 - val_accuracy: 0.5748 - val_loss: 1.1654\n",
            "Epoch 87/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.6589 - loss: 0.8149 - val_accuracy: 0.5748 - val_loss: 1.1654\n",
            "Epoch 88/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.6580 - loss: 0.8146 - val_accuracy: 0.5748 - val_loss: 1.1656\n",
            "Epoch 89/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6600 - loss: 0.8106 - val_accuracy: 0.5754 - val_loss: 1.1656\n",
            "Epoch 90/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6574 - loss: 0.8161âœ… Saved model at epoch 90\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.6574 - loss: 0.8160 - val_accuracy: 0.5765 - val_loss: 1.1659\n",
            "Epoch 91/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.6671 - loss: 0.8047 - val_accuracy: 0.5765 - val_loss: 1.1659\n",
            "Epoch 92/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.6631 - loss: 0.8065 - val_accuracy: 0.5765 - val_loss: 1.1659\n",
            "Epoch 93/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6615 - loss: 0.8191 - val_accuracy: 0.5768 - val_loss: 1.1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "import tensorflow as tf\n",
        "\n",
        "model = load_model(\"vgg19_fer_epoch_90.keras\")  # Or epoch_95.keras if that exists\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(1e-6),  # Stick to this; donâ€™t change\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train_rgb, y_train))\n",
        "train_ds = train_ds.shuffle(10000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_valid_rgb, y_valid))\n",
        "valid_ds = valid_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "class SaveEvery5Epochs(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            self.model.save(f\"vgg19_fer_epoch_{epoch+1}.keras\")\n",
        "            print(f\"âœ… Saved model at epoch {epoch+1}\")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "\n",
        "\n",
        "history_resume = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    initial_epoch=90,\n",
        "    epochs=100,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery5Epochs()],\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMYVUMZIM3rd",
        "outputId": "fe97d638-6ee0-4313-a8fa-4acaf0c88f9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 13 variables whereas the saved optimizer has 17 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.6557 - loss: 0.8132 - val_accuracy: 0.5765 - val_loss: 1.1660 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 35ms/step - accuracy: 0.6644 - loss: 0.8036 - val_accuracy: 0.5768 - val_loss: 1.1659 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6575 - loss: 0.8121 - val_accuracy: 0.5759 - val_loss: 1.1662 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6619 - loss: 0.8083 - val_accuracy: 0.5754 - val_loss: 1.1661 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6608 - loss: 0.8063\n",
            "Epoch 95: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
            "âœ… Saved model at epoch 95\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6608 - loss: 0.8063 - val_accuracy: 0.5759 - val_loss: 1.1662 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.6629 - loss: 0.8015 - val_accuracy: 0.5759 - val_loss: 1.1663 - learning_rate: 5.0000e-07\n",
            "Epoch 97/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6569 - loss: 0.8163 - val_accuracy: 0.5759 - val_loss: 1.1662 - learning_rate: 5.0000e-07\n",
            "Epoch 98/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6638 - loss: 0.8048\n",
            "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.6638 - loss: 0.8048 - val_accuracy: 0.5762 - val_loss: 1.1662 - learning_rate: 5.0000e-07\n",
            "Epoch 99/100\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6617 - loss: 0.8037 - val_accuracy: 0.5762 - val_loss: 1.1663 - learning_rate: 2.5000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"vgg19_fer_epoch_100.keras\")\n",
        "\n",
        "history_resume = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    initial_epoch=100,\n",
        "    epochs=120,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, reduce_lr, SaveEvery5Epochs()],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5JH4CBRPLc0",
        "outputId": "949af40e-082c-42f0-f2cf-1fb578abb984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 42ms/step - accuracy: 0.6627 - loss: 0.8085 - val_accuracy: 0.5762 - val_loss: 1.1663 - learning_rate: 2.5000e-07\n",
            "Epoch 102/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36ms/step - accuracy: 0.6575 - loss: 0.8103 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 2.5000e-07\n",
            "Epoch 103/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.6614 - loss: 0.8108 - val_accuracy: 0.5762 - val_loss: 1.1663 - learning_rate: 2.5000e-07\n",
            "Epoch 104/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6634 - loss: 0.8103\n",
            "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.2499999968440534e-07.\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.6634 - loss: 0.8103 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 2.5000e-07\n",
            "Epoch 105/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6592 - loss: 0.8069âœ… Saved model at epoch 105\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6592 - loss: 0.8069 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 1.2500e-07\n",
            "Epoch 106/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6623 - loss: 0.8100 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 1.2500e-07\n",
            "Epoch 107/120\n",
            "\u001b[1m448/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6588 - loss: 0.8121\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 6.249999984220267e-08.\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.6588 - loss: 0.8121 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 1.2500e-07\n",
            "Epoch 108/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6607 - loss: 0.8103 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 6.2500e-08\n",
            "Epoch 109/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.6613 - loss: 0.8084 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 6.2500e-08\n",
            "Epoch 110/120\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6632 - loss: 0.8070\n",
            "Epoch 110: ReduceLROnPlateau reducing learning rate to 3.1249999921101335e-08.\n",
            "âœ… Saved model at epoch 110\n",
            "\u001b[1m449/449\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.6632 - loss: 0.8070 - val_accuracy: 0.5765 - val_loss: 1.1663 - learning_rate: 6.2500e-08\n",
            "Epoch 111/120\n",
            "\u001b[1m 55/449\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - accuracy: 0.6586 - loss: 0.8163"
          ]
        }
      ]
    }
  ]
}